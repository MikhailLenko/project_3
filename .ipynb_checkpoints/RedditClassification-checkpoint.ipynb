{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_p = 'https://www.reddit.com/r/progressive.json'\n",
    "url_c = 'https://www.reddit.com/r/Conservative.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-agent':'Bleep blot blort 0.11'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_p = requests.get(url_p, headers=headers)\n",
    "res_c = requests.get(url_c, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_p = res_p.json()\n",
    "dict_c = res_c.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "p_posts = []\n",
    "after = None\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else:\n",
    "        params = {'after':after}\n",
    "    \n",
    "    res = requests.get(url_p, params=params, headers=headers)\n",
    "    dict_p = res.json()\n",
    "    p_posts.extend(dict_p['data']['children'])\n",
    "    after = dict_p['data']['after']\n",
    "    \n",
    "    time.sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame(p_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of  progressive documents\n",
    "\n",
    "prog = []\n",
    "for i in range(len(p_posts)):\n",
    "    prog.append(df_p['data'][i]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate progressive corpus by rendering list as DataFrame\n",
    "\n",
    "prog_df = pd.DataFrame(prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling documents with their source, p=1, c=0\n",
    "\n",
    "prog_df['source'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "c_posts = []\n",
    "after = None\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else:\n",
    "        params = {'after':after}\n",
    "        \n",
    "    res = requests.get(url_c, params=params, headers=headers)\n",
    "    dict_c = res.json()\n",
    "    c_posts.extend(dict_c['data']['children'])\n",
    "    after = dict_c['data']['after']\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.DataFrame(c_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of  conservative documents\n",
    "\n",
    "cons = []\n",
    "for i in range(len(c_posts)):\n",
    "    cons.append(df_c['data'][i]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate conservative corpus by rendering list as DataFrame\n",
    "\n",
    "cons_df = pd.DataFrame(cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling documents with their source, p=1, c=0\n",
    "\n",
    "cons_df['source'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master DataFrame, with just progressive/conservative corpora matched with their labels\n",
    "\n",
    "df = prog_df.append(cons_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data munging complete, corpus of ~5k labeled documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./initialcorpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./initialcorpus.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onto preprocessing data for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: source, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline model: No issue with prior probability\n",
    "\n",
    "df['source'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining features (X) and target (y)\n",
    "\n",
    "X = df['0']\n",
    "y = df['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for Count Vectorized logistic regression\n",
    "\n",
    "pipe_cv_lr = Pipeline([('cvec', CountVectorizer()),\n",
    "                           ('lr', LogisticRegression())\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for Count Vectorized MultiNomial Naive Bayes model\n",
    "\n",
    "pipe_cv_mnb = Pipeline([('cvec', CountVectorizer()),\n",
    "                        ('mnb', MultinomialNB())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for TFIDF vectorized logistic regression\n",
    "\n",
    "pipe_tvec_lr = Pipeline([('tvec', TfidfVectorizer()),\n",
    "                             ('lr', LogisticRegression())\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for TFIDF vectorized logistic regression\n",
    "\n",
    "pipe_tvec_mnb = Pipeline([('tvec', TfidfVectorizer()),\n",
    "                          ('mnb', MultinomialNB())\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikhaillenko/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9438997821350763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearching through Count Vectorized logistic regression\n",
    "\n",
    "pipe_params_cvec_lr = {\n",
    "    'cvec__max_features': [5000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    \n",
    "}\n",
    "\n",
    "gs_cv_lr = GridSearchCV(pipe_cv_lr, param_grid=pipe_params_cvec_lr, cv=3)\n",
    "gs_cv_lr.fit(X_train, y_train)\n",
    "print(gs_cv_lr.best_score_)\n",
    "gs_cv_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9986383442265795\n",
      "Test score: 0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "# ACCURACY SCORE for CountVectorized Logistic Regression model\n",
    "\n",
    "print(f\"Training score: {gs_cv_lr.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {gs_cv_lr.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions for confusion matrix\n",
    "\n",
    "y_pred_cv_lr = gs_cv_lr.predict(X_test)\n",
    "cm_cv_lr = confusion_matrix(y_test, y_pred_cv_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negatives</th>\n",
       "      <th>Predicted Positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negatives</th>\n",
       "      <td>604</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positives</th>\n",
       "      <td>5</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Negatives  Predicted Positives\n",
       "Actual Negatives                  604                   12\n",
       "Actual Positives                    5                  603"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFUSION MATRIX for CountVectorized Logistic Regression model\n",
    "\n",
    "cm_cv_lr = pd.DataFrame(data=cm_cv_lr,\n",
    "                     index=['Actual Negatives','Actual Positives'],\n",
    "                     columns=['Predicted Negatives','Predicted Positives'])\n",
    "cm_cv_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8818082788671024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 4500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearching through Count Vectorized multinominal naive Bayes\n",
    "\n",
    "pipe_params_cvec_mnb = {\n",
    "    'cvec__max_features': [4500,5000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'cvec__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "gs_cv_mnb = GridSearchCV(pipe_cv_mnb, param_grid=pipe_params_cvec_mnb, cv=3)\n",
    "gs_cv_mnb.fit(X_train, y_train)\n",
    "print(gs_cv_mnb.best_score_)\n",
    "gs_cv_mnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9665032679738562\n",
      "Test score: 0.9199346405228758\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score for Count Vectorized MNB model\n",
    "\n",
    "print(f\"Training score: {gs_cv_mnb.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {gs_cv_mnb.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions for confusion matrix\n",
    "\n",
    "y_pred_cv_mnb = gs_cv_mnb.predict(X_test)\n",
    "cm_cv_mnb = confusion_matrix(y_test, y_pred_cv_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negatives</th>\n",
       "      <th>Predicted Positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negatives</th>\n",
       "      <td>559</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positives</th>\n",
       "      <td>41</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Negatives  Predicted Positives\n",
       "Actual Negatives                  559                   57\n",
       "Actual Positives                   41                  567"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFUSION MATRIX for Count Vectorized multi-nomial naive Bayes.\n",
    "\n",
    "cm_cv_mnb = pd.DataFrame(data=cm_cv_mnb,\n",
    "                     index=['Actual Negatives','Actual Positives'],\n",
    "                     columns=['Predicted Negatives','Predicted Positives'])\n",
    "cm_cv_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikhaillenko/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9098583877995643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.9,\n",
       " 'tvec__max_features': 4500,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearching through TFIDF logistic regression\n",
    "\n",
    "pipe_params_tvec_lr = {\n",
    "    'tvec__max_features': [4500,5000],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'tvec__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "gs_tvec_lr = GridSearchCV(pipe_tvec_lr, param_grid=pipe_params_tvec_lr, cv=3)\n",
    "gs_tvec_lr.fit(X_train, y_train)\n",
    "print(gs_tvec_lr.best_score_)\n",
    "gs_tvec_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.9847494553376906\n",
      "Test score: 0.9436274509803921\n"
     ]
    }
   ],
   "source": [
    "# ACCURACY SCORE for TFIDF Logistic Regression model\n",
    "\n",
    "print(f\"Testing score: {gs_tvec_lr.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {gs_tvec_lr.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negatives</th>\n",
       "      <th>Predicted Positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negatives</th>\n",
       "      <td>571</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positives</th>\n",
       "      <td>24</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Negatives  Predicted Positives\n",
       "Actual Negatives                  571                   45\n",
       "Actual Positives                   24                  584"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFUSION MATRIX for TFIDF / LR model\n",
    "\n",
    "y_pred_tvec_lr = gs_tvec_lr.predict(X_test)\n",
    "cm_tvec_lr = confusion_matrix(y_test, y_pred_tvec_lr)\n",
    "\n",
    "cm_tvec_lr = pd.DataFrame(data=cm_tvec_lr,\n",
    "                     index=['Actual Negatives','Actual Positives'],\n",
    "                     columns=['Predicted Negatives','Predicted Positives'])\n",
    "cm_tvec_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8935185185185185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.9,\n",
       " 'tvec__max_features': 4500,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__stop_words': None}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearching through TFIDF / MNB model\n",
    "\n",
    "pipe_params_tvec_mnb = {\n",
    "    'tvec__max_features': [4500,5000],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'tvec__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "gs_tvec_mnb = GridSearchCV(pipe_tvec_mnb, param_grid=pipe_params_tvec_mnb, cv=3)\n",
    "gs_tvec_mnb.fit(X_train, y_train)\n",
    "print(gs_tvec_mnb.best_score_)\n",
    "gs_tvec_mnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9722222222222222\n",
      "Test score: 0.9264705882352942\n"
     ]
    }
   ],
   "source": [
    "# ACCURACY SCORES for TFIDF / MNB model\n",
    "\n",
    "print(f\"Training score: {gs_tvec_mnb.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {gs_tvec_mnb.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negatives</th>\n",
       "      <th>Predicted Positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negatives</th>\n",
       "      <td>561</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positives</th>\n",
       "      <td>35</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Negatives  Predicted Positives\n",
       "Actual Negatives                  561                   55\n",
       "Actual Positives                   35                  573"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFUSION MATRIX for TFIDF / MNB model\n",
    "\n",
    "y_pred_tvec_mnb = gs_tvec_mnb.predict(X_test)\n",
    "cm_tvec_mnb = confusion_matrix(y_test, y_pred_tvec_mnb)\n",
    "\n",
    "cm_tvec_mnb = pd.DataFrame(data=cm_tvec_mnb,\n",
    "                     index=['Actual Negatives','Actual Positives'],\n",
    "                     columns=['Predicted Negatives','Predicted Positives'])\n",
    "cm_tvec_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikhaillenko/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing features using GridSearch optimized parameters\n",
    "\n",
    "# The purpose of the following is to discover which tokens (words) are most highly distinctive of particular threads.\n",
    "# To do this, coefficients are needed. GridSearch outputs optimal model configuration, but does not create that\n",
    "# model in a way that allows us to extract feature coefficients. So, we create the model specified by GridSearch\n",
    "# to access feature coefficients.\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english', \n",
    "                       max_df=0.9, \n",
    "                       min_df=2, \n",
    "                       ngram_range=(1,1),\n",
    "                       max_features=5000)\n",
    "\n",
    "X_train_vec = cvec.fit_transform(X_train)\n",
    "X_test_vec = cvec.transform(X_test)\n",
    "\n",
    "make_model = LogisticRegression()\n",
    "please_work = make_model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>impeachment</th>\n",
       "      <td>2.469504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warren</th>\n",
       "      <td>2.079206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>1.884390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elizabeth</th>\n",
       "      <td>1.520687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congress</th>\n",
       "      <td>1.407338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>1.403895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senate</th>\n",
       "      <td>1.380857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cushy</th>\n",
       "      <td>1.363780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ban</th>\n",
       "      <td>1.317647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>1.301293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legal</th>\n",
       "      <td>1.287578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alec</th>\n",
       "      <td>1.259370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abortion</th>\n",
       "      <td>1.258756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>republicans</th>\n",
       "      <td>1.247594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>1.242115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>1.220841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>1.210092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>1.196809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>door</th>\n",
       "      <td>1.148744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child</th>\n",
       "      <td>1.139156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1.125017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alexander</th>\n",
       "      <td>1.118674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>progressive</th>\n",
       "      <td>1.117821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promised</th>\n",
       "      <td>1.111830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war</th>\n",
       "      <td>1.109120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latest</th>\n",
       "      <td>1.108546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broadband</th>\n",
       "      <td>1.106713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wealth</th>\n",
       "      <td>1.097993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cia</th>\n",
       "      <td>1.084396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raising</th>\n",
       "      <td>1.080474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requiring</th>\n",
       "      <td>-1.062938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ice</th>\n",
       "      <td>-1.071693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confiscation</th>\n",
       "      <td>-1.079529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>americanism</th>\n",
       "      <td>-1.096657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kamala</th>\n",
       "      <td>-1.097292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <td>-1.130974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>-1.134092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accurate</th>\n",
       "      <td>-1.142864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>-1.160668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breitbart</th>\n",
       "      <td>-1.176931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reporter</th>\n",
       "      <td>-1.186078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release</th>\n",
       "      <td>-1.188911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npc</th>\n",
       "      <td>-1.192307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killed</th>\n",
       "      <td>-1.198266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs</th>\n",
       "      <td>-1.210444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illegal</th>\n",
       "      <td>-1.256017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocasio</th>\n",
       "      <td>-1.262896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cortez</th>\n",
       "      <td>-1.262896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raids</th>\n",
       "      <td>-1.299310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald</th>\n",
       "      <td>-1.313246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>-1.333970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omar</th>\n",
       "      <td>-1.373933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antifa</th>\n",
       "      <td>-1.497428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immigration</th>\n",
       "      <td>-1.499251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialism</th>\n",
       "      <td>-1.517680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rapinoe</th>\n",
       "      <td>-1.639018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citizenship</th>\n",
       "      <td>-1.676172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media</th>\n",
       "      <td>-2.140835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epstein</th>\n",
       "      <td>-2.242767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aoc</th>\n",
       "      <td>-2.593138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4524 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "impeachment   2.469504\n",
       "warren        2.079206\n",
       "opinion       1.884390\n",
       "elizabeth     1.520687\n",
       "congress      1.407338\n",
       "think         1.403895\n",
       "senate        1.380857\n",
       "cushy         1.363780\n",
       "ban           1.317647\n",
       "tax           1.301293\n",
       "legal         1.287578\n",
       "alec          1.259370\n",
       "abortion      1.258756\n",
       "republicans   1.247594\n",
       "fox           1.242115\n",
       "housing       1.220841\n",
       "beto          1.210092\n",
       "power         1.196809\n",
       "door          1.148744\n",
       "child         1.139156\n",
       "2020          1.125017\n",
       "alexander     1.118674\n",
       "progressive   1.117821\n",
       "promised      1.111830\n",
       "war           1.109120\n",
       "latest        1.108546\n",
       "broadband     1.106713\n",
       "wealth        1.097993\n",
       "cia           1.084396\n",
       "raising       1.080474\n",
       "...                ...\n",
       "requiring    -1.062938\n",
       "ice          -1.071693\n",
       "confiscation -1.079529\n",
       "americanism  -1.096657\n",
       "kamala       -1.097292\n",
       "flag         -1.130974\n",
       "tech         -1.134092\n",
       "accurate     -1.142864\n",
       "video        -1.160668\n",
       "breitbart    -1.176931\n",
       "reporter     -1.186078\n",
       "release      -1.188911\n",
       "npc          -1.192307\n",
       "killed       -1.198266\n",
       "vs           -1.210444\n",
       "illegal      -1.256017\n",
       "ocasio       -1.262896\n",
       "cortez       -1.262896\n",
       "raids        -1.299310\n",
       "donald       -1.313246\n",
       "soccer       -1.333970\n",
       "omar         -1.373933\n",
       "antifa       -1.497428\n",
       "immigration  -1.499251\n",
       "socialism    -1.517680\n",
       "rapinoe      -1.639018\n",
       "citizenship  -1.676172\n",
       "media        -2.140835\n",
       "epstein      -2.242767\n",
       "aoc          -2.593138\n",
       "\n",
       "[4524 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.DataFrame(please_work.coef_, columns=cvec.get_feature_names()).T\n",
    "coef.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.848996\n",
       "Name: democratic, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef.T['democratic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.9574\n",
       "Name: democrat, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef.T['democrat']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
